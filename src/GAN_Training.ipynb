{"cells":[{"cell_type":"markdown","source":["# Introduction\n","This Google Colab notebook aims to implement and train a Generative Adversarial Network (GAN) to generate surrealist art.\n","The GAN is constructed using a two-part architecture: a Generator model that synthesizes new images from random noise, and a Discriminator model that evaluates whether an image is real or generated. By training on a dataset of surrealist art images, the GAN learns to generate novel images in a similar style, making it an exciting application of deep learning in the field of art generation.\n","\n"],"metadata":{"id":"IqZRZsaZR3Oq"}},{"cell_type":"markdown","source":["# Purpose\n","### The primary objectives of this project are:\n","\n","* **Preprocessing:** Load and preprocess a dataset of surrealist art images into a suitable format for training.\n","* **GAN Architecture:** Build and define both Generator and Discriminator models, which form the core components of the GAN architecture.\n","* **Training:** Train the GAN on the surrealist art dataset, utilizing a WGAN-GP (Wasserstein GAN with Gradient Penalty) approach to enhance training stability.\n","* **Evaluation:** Track training progress through loss metrics and visualize generated images at various stages to assess the GAN's output quality.\n","* **Saving Models:** Save the trained Generator and Discriminator models to Google Drive for future use or further refinement.\n","\n","\n"],"metadata":{"id":"fCP3Qt_dSB1x"}},{"cell_type":"markdown","source":["Overall, this project demonstrates how deep learning can be applied in the realm of art generation, producing new images inspired by surrealist artwork. By the end of this notebook, you will have a trained GAN capable of generating surrealist-style images, along with models saved for future use or modification."],"metadata":{"id":"_4dCLWDPS7HS"}},{"cell_type":"markdown","source":["# Imports & Mount Google Drive\n","This section mounts Google Drive to access datasets and save results directly to it:"],"metadata":{"id":"fk2ajhu7Psu-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZsHCj-FG6bj"},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","import librosa\n","import tensorflow as tf\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from matplotlib import colors, pyplot as plt\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n","from tensorflow.keras.layers import Input, Dense, Reshape, BatchNormalization, LeakyReLU, Conv2DTranspose, Conv2D, Flatten, Dropout, MaxPooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","from tensorflow.keras.optimizers import Adam\n","import h5py  # for saving to HDF5 format\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import distutils as _distutils\n","import importlib\n","import inspect as _inspect\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["# Paths and Preprocessing Functions\n","Defines the paths to the necessary directories and includes functions to preprocess art images:"],"metadata":{"id":"WEGNKqJvPzMH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_md_Wt-HDgq"},"outputs":[],"source":["# Define paths\n","spectrogram_dir = '/content/drive/MyDrive/COSC_5470/spectrograms' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/spectrograms'\n","art_dataset_dir = '/content/drive/MyDrive/COSC_5470/AI_Abstract_Surrealism_DataSet' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/AI_LD_surrealism'\n","label_csv_path = '/content/drive/MyDrive/COSC_5470/song_metadata.csv' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/song_metadata.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7orQmHPIuEE-"},"outputs":[],"source":["def preprocess_art_images(art_dataset_dir, target_size=(256, 256)):\n","    images = []\n","    for img_file in os.listdir(art_dataset_dir):\n","        img_path = os.path.join(art_dataset_dir, img_file)\n","\n","        # Check if the file is a valid image\n","        try:\n","            img = load_img(img_path, target_size=target_size)\n","            img = img_to_array(img)\n","\n","            # Normalize the image to [-1, 1]\n","            img = (img - 127.5) / 127.5\n","\n","            images.append(img)\n","        except Exception as e:\n","            print(f\"Skipping file {img_file} due to error: {e}\")\n","\n","    return np.array(images)"]},{"cell_type":"markdown","source":["# Loading and Saving Preprocessed Images\n","Loads and preprocesses art images, and optionally saves them for later use:"],"metadata":{"id":"SM3d4Ah-P7FA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"okuoyJ-6uHUs"},"outputs":[],"source":["# Load and preprocess images before training\n","art_images = preprocess_art_images(art_dataset_dir, target_size=(256, 256))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMKGLdvFuIU6"},"outputs":[],"source":["np.save('processed_art_images.npy', art_images)  # Save for later use or immediate training"]},{"cell_type":"markdown","source":["# Visualization Function\n","Provides a utility function to visualize a selection of preprocessed images:"],"metadata":{"id":"bR44vDoWP11-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"D757VvrcDzVj"},"outputs":[],"source":["# Function to visualize data\n","def visualize_data(images, n=5):\n","    plt.figure(figsize=(10, 10))\n","    for i in range(n):\n","        ax = plt.subplot(1, n, i + 1)\n","        img = 0.5 * images[np.random.randint(0, len(images))] + 0.5  # Rescale images to [0, 1]\n","        plt.imshow(img)\n","        plt.axis('off')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLEfPul2Dskl"},"outputs":[],"source":["visualize_data(art_images)"]},{"cell_type":"markdown","source":["# Loading and Saving Preprocessed Images\n","Loads and preprocesses art images, and optionally saves them for later use:"],"metadata":{"id":"p3_wpTNcQAFz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GMvIOxluJ58"},"outputs":[],"source":["# Build Generator Model\n","def build_generator(latent_dim):\n","    generator_input = Input(shape=(latent_dim,))\n","    x = Dense(128 * 64 * 64)(generator_input)\n","    x = LeakyReLU()(x)\n","    x = Reshape((64, 64, 128))(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2DTranspose(128, 5, strides=2, padding='same')(x)\n","    x = LeakyReLU()(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2DTranspose(64, 5, strides=2, padding='same')(x)\n","    x = LeakyReLU()(x)\n","    x = Conv2DTranspose(3, 7, activation='tanh', padding='same')(x)\n","    generator = Model(inputs=generator_input, outputs=x)\n","    return generator\n","\n","\n","# Build Discriminator Model\n","def build_discriminator(image_shape):\n","    discriminator_input = Input(shape=image_shape)\n","    x = Conv2D(64, 5, strides=2, padding='same')(discriminator_input)\n","    x = LeakyReLU()(x)\n","    x = Dropout(0.4)(x)\n","    x = Conv2D(128, 5, strides=2, padding='same')(x)\n","    x = LeakyReLU()(x)\n","    x = Dropout(0.4)(x)\n","    x = Conv2D(256, 5, strides=2, padding='same')(x)\n","    x = LeakyReLU()(x)\n","    x = Dropout(0.4)(x)\n","    x = Flatten()(x)\n","    x = Dense(1)(x)\n","    discriminator = Model(inputs=discriminator_input, outputs=x)\n","    return discriminator"]},{"cell_type":"markdown","source":["# Gradient Penalty\n","Defines a function to compute the gradient penalty for training:"],"metadata":{"id":"31ZfQV8YRVE5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxGrCEIbT54x"},"outputs":[],"source":["# Function to compute gradient penalty\n","def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n","    alpha = np.random.random((real_samples.shape[0], 1, 1, 1))\n","    interpolates = alpha * real_samples + (1 - alpha) * fake_samples\n","    with tf.GradientTape() as tape:\n","        tape.watch(interpolates)\n","        validity_interpolates = discriminator(interpolates, training=True)\n","    gradients = tape.gradient(validity_interpolates, [interpolates])[0]\n","    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n","    gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n","    return gradient_penalty\n"]},{"cell_type":"markdown","source":["# Training the GAN\n","Includes the main training loop for the GAN:"],"metadata":{"id":"5mGpnKvIRX5g"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykDA1k0yuNEf"},"outputs":[],"source":["# GAN Training Loop\n","# Training Function\n","def train_gan(generator, discriminator, generator_optimizer, discriminator_optimizer, images, epochs, batch_size, latent_dim, lambda_gp, scheduler):\n","    real_label = -1  # Labels for the \"real\" and \"fake\" samples\n","    fake_label = 1\n","    for epoch in range(epochs):\n","        for _ in range(images.shape[0] // batch_size):\n","            # Training Discriminator\n","            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","            noise = tf.convert_to_tensor(noise, dtype=tf.float32)  # Convert noise to tensor\n","            real_imgs = images[np.random.randint(0, images.shape[0], batch_size)]\n","            real_imgs = tf.convert_to_tensor(real_imgs, dtype=tf.float32)  # Convert real images to tensor\n","            gen_imgs = generator(noise, training=True)\n","\n","            with tf.GradientTape() as tape:\n","                real_loss = discriminator(real_imgs, training=True)\n","                fake_loss = discriminator(gen_imgs, training=True)\n","                gp = compute_gradient_penalty(discriminator, real_imgs, gen_imgs)\n","                d_loss = fake_loss - real_loss + lambda_gp * gp\n","            d_gradients = tape.gradient(d_loss, discriminator.trainable_variables)\n","            discriminator_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))\n","\n","            # Training Generator\n","            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","            noise = tf.convert_to_tensor(noise, dtype=tf.float32)  # Convert noise to tensor again for generator\n","            with tf.GradientTape() as tape:\n","                gen_imgs = generator(noise, training=True)\n","                g_loss = -discriminator(gen_imgs, training=True)\n","            g_gradients = tape.gradient(g_loss, generator.trainable_variables)\n","            generator_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))\n","\n","        # Output training progress\n","        print(f\"Epoch {epoch + 1}/{epochs}, D Loss: {tf.reduce_mean(d_loss)}, G Loss: {tf.reduce_mean(g_loss)}\")\n","        if (epoch + 1) % 10 == 0:\n","            visualize_data(gen_imgs.numpy(), n=5)  # Visualize generated images every 10 epochs\n","\n"]},{"cell_type":"markdown","source":["# Saving Generated Images\n","Defines a function to save generated images from the generator:"],"metadata":{"id":"b_McWFD8RcGM"}},{"cell_type":"code","source":["def save_images(epoch, generator, latent_dim, image_save_dir=\"saved_images\"):\n","    r, c = 5, 5\n","    noise = np.random.normal(0, 1, (r * c, latent_dim))\n","    gen_imgs = generator.predict(noise)\n","    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n","    os.makedirs(image_save_dir, exist_ok=True)\n","    fig, axs = plt.subplots(r, c)\n","    cnt = 0\n","    for i in range(r):\n","        for j in range(c):\n","            axs[i, j].imshow(gen_imgs[cnt, :, :, :], cmap='gray')\n","            axs[i, j].axis('off')\n","            cnt += 1\n","    fig.savefig(f\"{image_save_dir}/epoch_{epoch}.png\")\n","    plt.close()"],"metadata":{"id":"rANDrNukRefR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Setting Up and Training the GAN\n","Sets hyperparameters, initializes models, and begins training:"],"metadata":{"id":"jkF7OqY2Rg17"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21406,"status":"ok","timestamp":1714455930156,"user":{"displayName":"Sophia C","userId":"18357763148073221823"},"user_tz":240},"id":"INYFcmUTuLW8","outputId":"db471ede-582d-4e1d-d742-0837fc77272f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Skipping file .DS_Store due to error: cannot identify image file <_io.BytesIO object at 0x7cbaa71c1c60>\n"]}],"source":["# Set hyperparameters and paths\n","latent_dim = 100\n","epochs = 100\n","batch_size = 16\n","lambda_gp = 10\n","art_dataset_dir = '/content/drive/MyDrive/COSC_5470/AI_Abstract_Surrealism_DataSet' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/AI_LD_surrealism'\n","images = preprocess_art_images(art_dataset_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zLQbWFDRuPoB"},"outputs":[],"source":["# Initialize models and optimizers\n","generator = build_generator(latent_dim)\n","discriminator = build_discriminator((256, 256, 3))\n","generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n","discriminator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RkgmxVijUubx"},"outputs":[],"source":["train_gan(generator, discriminator, generator_optimizer, discriminator_optimizer, images, epochs, batch_size, latent_dim, lambda_gp, None)\n"]},{"cell_type":"markdown","source":["# Saving the Models\n","Saves the trained models to Google Drive for future use:"],"metadata":{"id":"HuFZxvUlRlpn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LkjAchDAuQyK"},"outputs":[],"source":["# Save the trained models\n","generator.save('/content/drive/My Drive/COSC_5470/saved_generator_model_final.keras')\n","discriminator.save('/content/drive/My Drive/COSC_5470/saved_discriminator_model_final.keras')\n","# gan.save('/content/drive/My Drive/COSC_5470/saved_gan_model_final.keras')"]},{"cell_type":"markdown","metadata":{"id":"hXKugrTy7YCy"},"source":["# Visualization of GAN Training Metrics\n","This section of the notebook visualizes GAN training metrics extracted from a log file. The log file contains information about each training epoch, including the losses for both the Discriminator and Generator models, which are key metrics for evaluating the GAN's training progress."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BTt3buK7WlX"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","import pandas as pd\n","\n","# Read the data from the uploaded file\n","file_path = '/content/drive/My Drive/COSC_5470/training_log1.txt'  # Ensure the path is correctly specified\n","\n","# Initialize lists to store the extracted data\n","epochs = []\n","d_losses = []\n","g_losses = []\n","\n","with open(file_path, 'r', encoding='utf-8-sig') as file:  # 'utf-8-sig' removes the BOM if present\n","    for line in file:\n","        if 'Epoch' in line:\n","            parts = line.split(',')\n","            epoch = int(parts[0].split(' ')[1].split('/')[0])  # Parsing the epoch number\n","            d_loss = float(parts[1].split(': ')[1])  # Parsing the discriminator loss\n","            g_loss = float(parts[2].split(': ')[1])  # Parsing the generator loss\n","\n","            epochs.append(epoch)\n","            d_losses.append(d_loss)\n","            g_losses.append(g_loss)\n","\n","# Create a DataFrame\n","data = pd.DataFrame({\n","    'Epoch': epochs,\n","    'Discriminator Loss': d_losses,\n","    'Generator Loss': g_losses\n","})\n","\n","# Plotting with Matplotlib and Seaborn\n","plt.figure(figsize=(14, 7))\n","plt.subplot(1, 2, 1)\n","sns.lineplot(x='Epoch', y='Discriminator Loss', data=data, label='Discriminator Loss')\n","sns.lineplot(x='Epoch', y='Generator Loss', data=data, label='Generator Loss')\n","plt.title('Loss During Training')\n","plt.grid(True)\n","\n","plt.subplot(1, 2, 2)\n","sns.lineplot(x='Epoch', y='Generator Loss', data=data)\n","plt.title('Generator Loss During Training')\n","plt.grid(True)\n","plt.show()\n","\n","# Interactive Plotting with Plotly\n","fig = px.line(data, x='Epoch', y=['Discriminator Loss', 'Generator Loss'],\n","              title='Interactive Training Metrics Visualization', labels={'value': 'Metric Value', 'variable': 'Metrics'})\n","fig.show()\n"]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"89jOhMvzRo-u"}}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOtaXu/T3LOz5Ps1gLVsKEv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}