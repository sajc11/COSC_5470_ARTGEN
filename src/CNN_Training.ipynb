{"cells":[{"cell_type":"markdown","source":["## Imports & Mounting Google Drive\n"],"metadata":{"id":"vJRnz0QgJ0Zj"}},{"cell_type":"markdown","source":["We start by mounting Google Drive to access the necessary datasets and files directly. This is essential for working with the spectrogram images, metadata, and any additional resources required for training the CNN model.\n","\n"],"metadata":{"id":"Xq_x-YRUJyJv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0TDVaUFSXYZ1"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import h5py  # for saving to HDF5 format\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')  # Mount Google Drive for accessing files\n"]},{"cell_type":"markdown","source":["# Path Definitions\n","We define paths to the directories containing spectrogram images, additional datasets, and the labels CSV file. These paths are crucial for loading data and associating labels with corresponding spectrograms."],"metadata":{"id":"RIxCTniBJ68f"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCiV_tviYE6A"},"outputs":[],"source":["# Define paths\n","# Assuming all spectrogram images are stored in a directory called 'spectrogram_dir'\n","spectrogram_dir = '/content/drive/MyDrive/COSC_5470/spectrograms' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/spectrograms'\n","art_dataset_dir = '/content/drive/MyDrive/COSC_5470/AI_Abstract_Surrealism_DataSet' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/AI_LD_surrealism'\n","label_csv_path = '/content/drive/MyDrive/COSC_5470/song_metadata.csv' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/song_metadata.csv'"]},{"cell_type":"markdown","source":["# Loading Labels\n","We define a function to read and process the labels from a CSV file. This function cleans up the data, mapping song titles to their valence and genre, and also creates a mapping for energy labels. This is important for preparing labels that will be used in training."],"metadata":{"id":"bhOfN67LKDbU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXBrKLqa8rNP"},"outputs":[],"source":["def load_labels(label_file):\n","    labels_df = pd.read_csv(label_file)\n","    labels_df['Title'] = labels_df['Title'].apply(lambda x: x.strip())  # Clean up whitespace\n","    file_to_valence_genre = labels_df.set_index('Title')[['Valence', 'Genre']].to_dict('index')\n","    file_to_energy = labels_df.set_index('Title')['Energy'].to_dict()\n","    return labels_df, file_to_valence_genre, file_to_energy\n","\n","labels_df, file_to_valence_genre, file_to_energy = load_labels(label_csv_path)\n","print (labels_df)\n","print (file_to_valence_genre)\n","print (file_to_energy)"]},{"cell_type":"markdown","source":["# Matching Labels to Spectrogram Files\n","We implement a function to match labels with corresponding spectrogram files. This function iterates over the song titles in the DataFrame and checks for matching files in the spectrogram directory, recording any unmatched titles for later review."],"metadata":{"id":"CrgeL3xEKKL5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SC3pvOSAatxt"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","def match_labels_to_files(df, spectrogram_dir):\n","    \"\"\"\n","    Matches each song name in the DataFrame with its corresponding spectrogram in the directory.\n","\n","    :param df: DataFrame containing song titles.\n","    :param spectrogram_dir: Directory containing spectrogram files.\n","    :return: Tuple of matched files and unmatched files.\n","    \"\"\"\n","    matched_files = {}\n","    unmatched_files = []\n","\n","    # Create a set of spectrogram filenames (without the .png extension) for easy lookup\n","    spectrogram_files = set(os.path.splitext(file)[0].strip().lower() for file in os.listdir(spectrogram_dir))\n","\n","    for idx, row in df.iterrows():\n","        title = row['Title'].strip().lower()\n","\n","        if title in spectrogram_files:\n","            matched_files[title] = os.path.join(spectrogram_dir, f\"{title}.png\")\n","        else:\n","            unmatched_files.append(title)\n","\n","    print(f'Matched files: {len(matched_files)}')\n","    print(f'Unmatched files: {len(unmatched_files)}')\n","\n","    return matched_files, unmatched_files\n","\n","# Usage Example:\n","label_csv_path = '/content/drive/MyDrive/COSC_5470/song_metadata.csv'\n","spectrogram_dir = '/content/drive/MyDrive/COSC_5470/spectrograms' #'/Users/sophiacastor/Dev/School/Y3_S24/COSC_5470/spectrograms'\n","\n","# Load Labels\n","labels_df = pd.read_csv(label_csv_path)\n","\n","# Match Labels to Files\n","matched_files, unmatched_files = match_labels_to_files(labels_df, spectrogram_dir)\n"]},{"cell_type":"markdown","source":["# Loading and Preprocessing Spectrograms\n","This function loads spectrogram images and preprocesses them into arrays, normalizing the pixel values and mapping them to labels. The resulting arrays are then split into training and testing sets for later model training."],"metadata":{"id":"9V-oKkiRKNxv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwJdw2M7dO0O"},"outputs":[],"source":["# Function to match spectrograms with labels and load them at their original resolution\n","def load_and_preprocess_spectrograms(spectrogram_dir, labels_df):\n","    X = []  # Spectrogram data\n","    y_valence = []  # Valence labels\n","    y_energy = []  # Energy labels\n","\n","    for index, row in labels_df.iterrows():\n","        file_path = os.path.join(spectrogram_dir, row['Title'] + '.png')\n","        if os.path.exists(file_path):\n","            image = load_img(file_path, color_mode='rgb')  # Load at original resolution\n","            image_array = img_to_array(image) / 255.0  # Normalize the image\n","            X.append(image_array)\n","            y_valence.append(row['Valence'])\n","            y_energy.append(row['Energy'])\n","\n","    return np.array(X), np.array(y_valence), np.array(y_energy)\n","\n","# Load and preprocess the data\n","X, y_valence, y_energy = load_and_preprocess_spectrograms(spectrogram_dir, labels_df)\n","\n","# Split the dataset into training and testing\n","X_train, X_test, y_valence_train, y_valence_test, y_energy_train, y_energy_test = train_test_split(\n","    X, y_valence, y_energy, test_size=0.2, random_state=42\n",")\n","\n","# Print a few preprocessed spectrograms to verify\n","plt.figure(figsize=(10, 5))\n","for i in range(min(5, len(X_train))):\n","    plt.subplot(1, 5, i+1)\n","    plt.imshow(X_train[i])\n","    plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrONbuMkYpzr"},"outputs":[],"source":["# Load and preprocess the data\n","X, y_valence, y_energy = load_and_preprocess_spectrograms(spectrogram_dir, labels_df)\n","\n","# Split the dataset into training and testing\n","X_train, X_test, y_valence_train, y_valence_test, y_energy_train, y_energy_test = train_test_split(\n","    X, y_valence, y_energy, test_size=0.2, random_state=42\n",")"]},{"cell_type":"code","source":["# Print out the shapes and some statistics\n","print(\"Spectrogram data shape:\", X.shape)\n","print(\"Valence label shape:\", y_valence.shape)\n","print(\"Energy label shape:\", y_energy.shape)\n","print(\"Spectrogram data - min:\", np.min(X), \"max:\", np.max(X))\n","print(\"Valence labels - min:\", np.min(y_valence), \"max:\", np.max(y_valence))\n","print(\"Energy labels - min:\", np.min(y_energy), \"max:\", np.max(y_energy))\n","\n","# Print out the shapes of the training and testing sets\n","print(\"Training set shape:\", X_train.shape)\n","print(\"Testing set shape:\", X_test.shape)\n","print(\"Training valence shape:\", y_valence_train.shape)\n","print(\"Testing valence shape:\", y_valence_test.shape)\n","print(\"Training energy shape:\", y_energy_train.shape)\n","print(\"Testing energy shape:\", y_energy_test.shape)\n"],"metadata":{"id":"ZH_2Xcl-LL_t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN Architecture\n","We define a Convolutional Neural Network (CNN) model for classifying spectrograms into valence and energy labels. The model consists of several convolutional layers, pooling layers, and dropout layers, ending with a dense layer for outputting valence and energy labels."],"metadata":{"id":"wIaUxRZQKSJ9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"aef_0g-edf2E"},"outputs":[],"source":["# Define the CNN architecture\n","def build_cnn_classifier(input_shape):\n","    input_layer = Input(shape=input_shape)\n","    x = Conv2D(32, (5, 5), activation='relu', padding='same', kernel_regularizer=l2(0.01))(input_layer)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Dropout(0.3)(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Dropout(0.3)(x)\n","\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Dropout(0.3)(x)\n","\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.01))(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Dropout(0.3)(x)\n","\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","\n","    # Change to a single output layer with 2 units for valence and energy\n","    outputs = Dense(2, activation='linear')(x)\n","\n","    model = Model(inputs=input_layer, outputs=outputs)\n","    model.compile(optimizer=RMSprop(learning_rate=0.0001, momentum=0.9),\n","              loss='mean_squared_error',  # Use one loss for the entire output\n","              metrics=['mean_squared_error'])\n","    return model\n","\n","# Initial"]},{"cell_type":"markdown","source":["# Data Augmentation\n","We set up an ImageDataGenerator to augment the training data. This includes applying rotations, shifts, shearing, and other transformations to the spectrograms to make the model more robust."],"metadata":{"id":"-WpkoyLlKVYD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a18xo9Audo_4"},"outputs":[],"source":["# Set up data augmentation for the training set\n","datagen = ImageDataGenerator(\n","    rotation_range=10,  # Increase rotation range\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    brightness_range=(0.8, 1.2),  # New augmentation for brightness\n","    fill_mode='nearest'\n",")\n","# datagen = ImageDataGenerator()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9k1ZjSQRfmC1"},"outputs":[],"source":["# Initialize the model\n","input_shape = X_train[0].shape\n","model = build_cnn_classifier((800, 1200, 3))  # Use the correct input shape"]},{"cell_type":"markdown","source":["# Training Parameters and Callbacks\n","We define training parameters such as batch size and epochs, along with callbacks like ModelCheckpoint, EarlyStopping, and LearningRateScheduler. These callbacks manage the training process, stopping it early if needed and saving the best-performing model."],"metadata":{"id":"dwZ7ccucKfH0"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HmVFA25xjqQD"},"outputs":[],"source":["# Set up the training parameters\n","batch_size = 16\n","epochs = 50\n","\n","# Define the path to save the best model\n","checkpoint_path = 'best_model.keras'\n","\n","# Combine the valence and energy labels for training into a single array\n","y_combined_train = np.hstack((y_valence_train.reshape(-1, 1), y_energy_train.reshape(-1, 1)))\n","\n","# Combine the valence and energy labels for testing into a single array\n","y_combined_test = np.hstack((y_valence_test.reshape(-1, 1), y_energy_test.reshape(-1, 1)))\n","\n","# Create ModelCheckpoint callback to save the best model during training\n","checkpoint = ModelCheckpoint(\n","    checkpoint_path,\n","    monitor='val_loss',\n","    save_best_only=True,\n","    verbose=1\n",")\n","\n","# Create EarlyStopping callback to halt training when validation loss stops improving\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    verbose=1,\n","    restore_best_weights=True\n",")\n","\n","# Function to update the learning rate\n","def scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","# Create LearningRateScheduler callback\n","lr_scheduler = LearningRateScheduler(scheduler, verbose=1)\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# Model Training\n","We train the model using the defined architecture, dataset, and callbacks, monitoring both training and validation losses."],"metadata":{"id":"vLncjYkVK2N7"}},{"cell_type":"code","source":["# Train the model\n","history = model.fit(\n","    datagen.flow(X_train, y_combined_train, batch_size=batch_size),\n","    steps_per_epoch=len(X_train) // batch_size,\n","    epochs=epochs,\n","    validation_data=(X_test, y_combined_test),\n","    callbacks=[checkpoint, early_stopping, lr_scheduler]\n",")\n","\n"],"metadata":{"id":"EDLE6vO9Kk8L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Saving the Model\n","We save the trained model in both Keras and HDF5 formats for future use."],"metadata":{"id":"HETzrqp9Kynx"}},{"cell_type":"code","source":["# Save the final model\n","model.save('/content/drive/MyDrive/COSC_5470/trained_cnn_model.keras')\n","model.save('/content/drive/MyDrive/COSC_5470/trained_cnn_model.h5')\n"],"metadata":{"id":"gZmfmvU0KrZX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss Visualization\n","We plot the training and validation losses over epochs to visualize the model's learning process."],"metadata":{"id":"x7pneohwKwAp"}},{"cell_type":"code","source":["\n","# Plotting training and validation loss\n","import matplotlib.pyplot as plt\n","\n","# Plotting training and validation loss\n","plt.figure(figsize=(12, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss Over Epochs')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"e1mfffpnKpzR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jax5ekphXizU"},"source":["\n","\n","---\n","\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNmivEhKSVZVl0BQ4NyAx+5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}